{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810c202e-b95f-434c-bc56-9e34740e48fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comment_id', 'parent_id', 'comment_author', 'comment_author_flair',\n",
      "       'comment_body', 'comment_score', 'post_id', 'post_title', 'post_author',\n",
      "       'post_author_flair', 'post_body', 'post_score', 'post_url',\n",
      "       'post_num_comments', 'post_date'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"'sarcasm_score' column not found in the dataset.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     df_filtered \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msarcasm_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msarcasm_score\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column not found in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Create a directed graph using NetworkX\u001b[39;00m\n\u001b[0;32m     21\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mDiGraph()\n",
      "\u001b[1;31mKeyError\u001b[0m: \"'sarcasm_score' column not found in the dataset.\""
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up Reddit API credentials\n",
    "client_id = 'Bkulv7ePr58Vu37vLBObAg'\n",
    "client_secret = 'jJTaqSbHFW-BXSYh0Br4copXSsiSWw'\n",
    "user_agent = 'Mozilla/5.0'\n",
    "\n",
    "# Initialize the PRAW Reddit instance\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# Define the Reddit post URL\n",
    "post_url = 'https://www.reddit.com/r/Asmongold/comments/1dfpot5/'  # Replace 'post_id' with the actual ID of the post\n",
    "\n",
    "# Get the submission (post) object\n",
    "submission = reddit.submission(url=post_url)\n",
    "\n",
    "# Convert the UTC timestamp to a human-readable format\n",
    "post_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Initialize a list to store post details and comments\n",
    "comments_dataset = []\n",
    "\n",
    "# Extract submission (post) details\n",
    "post_details = {\n",
    "    'post_id': submission.id,\n",
    "    'post_title': submission.title,\n",
    "    'post_author': submission.author.name if submission.author else 'deleted',\n",
    "    'post_author_flair': submission.author_flair_text,  # Extract the author's flair\n",
    "    'post_body': submission.selftext,\n",
    "    'post_score': submission.score,\n",
    "    'post_url': submission.url,\n",
    "    'post_num_comments': submission.num_comments,\n",
    "    'post_date': post_date  # Add post date\n",
    "}\n",
    "\n",
    "# Function to recursively extract comments and replies\n",
    "def extract_comments(comment, parent_id=None):\n",
    "    # Add the current comment to the dataset\n",
    "    comments_dataset.append({\n",
    "        'comment_id': comment.id,\n",
    "        'parent_id': parent_id,\n",
    "        'comment_author': comment.author.name if comment.author else 'deleted',\n",
    "        'comment_author_flair': comment.author_flair_text,  # Extract the comment author's flair\n",
    "        'comment_body': comment.body,\n",
    "        'comment_score': comment.score\n",
    "    })\n",
    "    \n",
    "    # Recursively extract replies\n",
    "    for reply in comment.replies:\n",
    "        extract_comments(reply, parent_id=comment.id)\n",
    "\n",
    "# Fetch all top-level comments and extract their replies\n",
    "submission.comments.replace_more(limit=None)  # Ensure all comments are loaded\n",
    "for top_level_comment in submission.comments.list():\n",
    "    extract_comments(top_level_comment)\n",
    "\n",
    "# Convert the comments dataset to a DataFrame\n",
    "df_user_publish_post = pd.DataFrame(comments_dataset)\n",
    "\n",
    "# user_post\n",
    "\n",
    "# user_publish_post\n",
    "df_user_publish_post['post_author'] = post_details['post_author']\n",
    "df_user_publish_post['post_id'] = post_details['post_id']\n",
    "df_user_publish_post.to_csv('user_publish_post.csv', index=False)\n",
    "\n",
    "df_post_postname = pd.DataFrame(comments_dataset)\n",
    "# post_(post name), add id in the first column\n",
    "df_post_postname['post_author'] = post_details['post_author']\n",
    "df_post_postname['post_title'] = post_details['post_title']\n",
    "df_post_postname['post_body'] = post_details['post_body']\n",
    "df_post_postname['post_date'] = post_details['post_date']\n",
    "df_post_postname['post_score'] = post_details['post_score']\n",
    "df_post_postname['post_num_comments'] = post_details['post_num_comments']\n",
    "\n",
    "df_post_postname.to_csv('post_postname.csv', index=False)\n",
    "\n",
    "'''\n",
    "# Add post details to each comment (so each row contains both post and comment info)\n",
    "df_comments['post_id'] = post_details['post_id']\n",
    "df_comments['post_title'] = post_details['post_title']\n",
    "df_comments['post_author'] = post_details['post_author']\n",
    "df_comments['post_author_flair'] = post_details['post_author_flair']\n",
    "df_comments['post_body'] = post_details['post_body']\n",
    "df_comments['post_score'] = post_details['post_score']\n",
    "df_comments['post_url'] = post_details['post_url']\n",
    "df_comments['post_num_comments'] = post_details['post_num_comments']\n",
    "df_comments['post_date'] = post_details['post_date']  # Add post date to each row\n",
    "\n",
    "# Save the comments and post data to a CSV file\n",
    "df_comments.to_csv('reddit_post_comments_with_flair_and_date.csv', index=False)\n",
    "'''\n",
    "print(\"Post and comments with flair and post date extracted and saved to 'reddit_post_comments_with_flair_and_date.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19813899-fac3-4ec3-82a6-29a0420bfdee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
